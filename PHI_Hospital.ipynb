{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos_df = pd.read_csv('abb_hos.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos = []\n",
    "\n",
    "for i in range(len(hos_df)):\n",
    "    dropna = hos_df.iloc[i].dropna()\n",
    "    \n",
    "    for j in range(len(dropna)):\n",
    "        if '병원' in dropna[j]:\n",
    "            dropna[j] = re.sub('병원', '', dropna[j])\n",
    "            hos.append(dropna[j])\n",
    "        if '대학교' in dropna[j]:\n",
    "            a = re.sub('(?m)학교.*$', '', dropna[j]) # '대학교' to end of the line\n",
    "            hos.append(a)\n",
    "            b = re.sub('대', '', a)\n",
    "            hos.append(b)\n",
    "        else:\n",
    "            hos.append(dropna[j])\n",
    "\n",
    "hos = list(set(hos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'건국|충북대|양산부산|CMC|단국대|계명대|가톨릭대학교성모|계명|KUMC|KHUH|본원|성모|DAMC|서울대|고려대|서울대학교 강남센터|DKUH|대구가톨릭대|전남|동아|이화여자|경상|KBSMS|건국대학교|고려대학교|연세대|중앙대|경북|울산대학교|단국대학교의과대학부속|순천향|중앙|아주|아주대|SNUH|GNUH|서울|전북|원광대학교|충북|AMC|강북삼성|칠곡경북|CBNUH|UUH|경북대|SMC|연건|원광|보라매|대구가톨릭대학교|신촌세브란스|전북대|전남대학교|울산|충남|CNUH|이화여자대학교의과대학|울산대|삼성서울|가톨릭대|영남대|영남대학교|순천향대학교|양산부산대|YUMC|한양|KNUCH|분당서울대|경상대|구가톨릭|JBUH|강남센터|AJOUMC|순천향대|SCHMC|영남|칠곡경북대학교|양산부산대학교|분당서울대학교|충남대|계명대학교동산|동아대|가톨릭|중앙대학교|한양대학교|WKUH|경상대학교|분당서울|아산|KNUH|고려|삼성|AJOU|강남세브란스|경북대학교|부산|PNUH|이화여자대|전북대학교|건국대|서울아산|SNUBH|PNUYH|전남대|연세대학교세브란스|충북대학교|단국|한양대|EUMC|경희대학교|CAUMC|KUH|부산대|HYUMC|경희|DSMC|DCMC|원광대|칠곡경북대|아주대학교|충남대학교|동아대학교|부산대학교|연세|경희대|서울대학교'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To add transform_regex.py\n",
    "\n",
    "'|'.join(hos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('phis.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos_phis = {}\n",
    "hos_phis_none = {}\n",
    "\n",
    "for i in range(len(dat)):\n",
    "    if pd.isnull(dat['의료기관명'][i]):\n",
    "        hos_phis_none[dat['NOTE_ID'][i]] = dat['note_text'][i]\n",
    "    else:\n",
    "        hos_phis[dat['NOTE_ID'][i]] = dat['note_text'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_origins = copy.deepcopy(hos_phis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy\n",
    "1. ~병원이라고 이름붙여진 것은 regex로 처리(`dropna[j] = re.sub('병원', '', dropna[j])`).\n",
    "2. ~병원으로 이름붙여지지 않는(예. 가톨릭) 것을 vocab으로 저장한다(transform_regex.py `\"\"\"+hos_kor+r\"\"\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call and pre-compile regex\n",
    "- 기존과는 용도가 약간 틀리지만 organizations 폴더에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "name_regex_path = './filters/regex/organizations/'\n",
    "file_list = os.listdir(name_regex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = []\n",
    "\n",
    "for file in file_list:\n",
    "    if file.endswith('_transformed.txt'):\n",
    "        with open(name_regex_path + file) as r:\n",
    "            patterns.append(re.compile(r.readline()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search non-detected PHIs (Type I error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_detected_hos_keys = []\n",
    "\n",
    "for notes in hos_phis.items():\n",
    "    phis = False\n",
    "    \n",
    "    for p in patterns:\n",
    "        if p.search(notes[1]) is not None: \n",
    "            phis = True\n",
    "            continue\n",
    "    \n",
    "    if phis == False:\n",
    "        non_detected_hos_keys.append(notes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_detected_hos_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 regex에 잡히지 않은 목록\n",
    "- [0] hos_kor에 일일이 추가하는 방향으로 간다.\n",
    "- [1] add regex\n",
    "- [2] 과 종류는 필요한 정보일 때도 있어 띄어쓰기 없이 붙어있는 경우만 취급한다. add regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type II error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_detected_staff_keys = []\n",
    "\n",
    "for notes in hos_phis_none.items():\n",
    "    phis = True\n",
    "    \n",
    "    for p in patterns:\n",
    "        if p.search(notes[1]) is None: \n",
    "            phis = False\n",
    "            continue\n",
    "    \n",
    "    if phis == True:\n",
    "        false_detected_staff_keys.append(notes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_detected_staff_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to asterisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_span(span_dict, note_dict):\n",
    "    for n in note_dict.items():\n",
    "        note_idx = n[0]\n",
    "        notes = n[1]\n",
    "        span_list = []\n",
    "\n",
    "        for p in patterns:\n",
    "            if p.search(notes) is not None:\n",
    "                #span_dict[note_idx].append(p.search(notes).span())\n",
    "                for m in re.finditer(p, notes):\n",
    "                    span_dict[note_idx].append(m.span())\n",
    "\n",
    "    return span_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hos_span_dict = defaultdict(list)\n",
    "raw_span = find_span(hos_span_dict, hos_phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phis in raw_span.items():\n",
    "    for spans in phis[1]:\n",
    "        hos_phis[phis[0]] = hos_phis[phis[0]][:spans[0]] + '*'*(spans[1]-spans[0]) + hos_phis[phis[0]][spans[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pd.DataFrame(columns = ['idx', 'origin', 'transformed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "tra = []\n",
    "ori = []\n",
    "\n",
    "\n",
    "for notes in hos_phis.items():\n",
    "    tra.append(notes[1])\n",
    "\n",
    "for notes in save_origins.items():\n",
    "    idx.append(notes[0])\n",
    "    ori.append(notes[1])\n",
    "\n",
    "if len(tra)==len(ori):\n",
    "    for i in range(len(tra)):\n",
    "        transformed.loc[i] = [idx[i], ori[i], tra[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>origin</th>\n",
       "      <th>transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313315846</td>\n",
       "      <td>[Conclusion]\\n\\r2012-04-05 outside CT를 판독하였음. ...</td>\n",
       "      <td>[Conclusion]\\n\\r2012-04-05 outside CT를 판독하였음. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300192556</td>\n",
       "      <td>[Conclusion]\\n\\rCategory 2 - Benign finding\\r\\...</td>\n",
       "      <td>[Conclusion]\\n\\rCategory 2 - Benign finding\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304614564</td>\n",
       "      <td>[Conclusion]\\n\\rLarge enhancing mass lesion in...</td>\n",
       "      <td>[Conclusion]\\n\\rLarge enhancing mass lesion in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                                             origin  \\\n",
       "0  313315846  [Conclusion]\\n\\r2012-04-05 outside CT를 판독하였음. ...   \n",
       "1  300192556  [Conclusion]\\n\\rCategory 2 - Benign finding\\r\\...   \n",
       "2  304614564  [Conclusion]\\n\\rLarge enhancing mass lesion in...   \n",
       "\n",
       "                                         transformed  \n",
       "0  [Conclusion]\\n\\r2012-04-05 outside CT를 판독하였음. ...  \n",
       "1  [Conclusion]\\n\\rCategory 2 - Benign finding\\r\\...  \n",
       "2  [Conclusion]\\n\\rLarge enhancing mass lesion in...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed.to_csv('transforemd_hospital_phis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
